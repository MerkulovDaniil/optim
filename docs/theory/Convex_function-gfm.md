# Convex function


## Convexity definitions

### Jensen’s inequality

The function $f(x)$, **which is defined on the convex set**
$S \subseteq \mathbb{R}^n$, is called **convex** on $S$, if:

$$
f(\lambda x_1 + (1 - \lambda)x_2) \le \lambda f(x_1) + (1 - \lambda)f(x_2)
$$

for any $x_1, x_2 \in S$ and $0 \le \lambda \le 1$.  
If the above inequality holds as strict inequality $x_1 \neq x_2$ and
$0 < \lambda < 1$, then the function is called strictly convex on $S$.

<div id="fig-convex_function">

![](convex_function.svg)

Figure 1: Difference between convex and non-convex function

</div>

> [!THEOREM]
>
> ### Jensen’s inequality
>
> <div>
>
> <div class="callout-theorem">
>
> Let $f(x)$ be a convex function on a convex set
> $X \subseteq \mathbb{R}^n$ and let $x_i \in X, 1 \leq i \leq m$, be
> arbitrary points from $X$. Then
>
> $$
> f\left( \sum_{i=1}^{m} \lambda_i x_i \right) \leq \sum_{i=1}^{m} \lambda_i f(x_i)
> $$
>
> for any $\lambda = [\lambda_1, \ldots, \lambda_m] \in \Delta_m$ -
> probability simplex.
>
> > [!PROOF]
> >
> > ### Proof
> >
> > <div>
> >
> > <div class="callout-proof" collapse="true">
> >
> > 1.  First, note that the point $\sum_{i=1}^{m} \lambda_i x_i$ as a
> >     convex combination of points from the convex set $X$ belongs to
> >     $X$.
> >
> > 2.  We will prove this by induction. For $m = 1$, the statement is
> >     obviously true, and for $m = 2$, it follows from the definition
> >     of a convex function.
> >
> > 3.  Assume it is true for all $m$ up to $m = k$, and we will prove
> >     it for $m = k + 1$. Let $\lambda \in \Delta{k+1}$ and
> >
> >     $$
> >      x = \sum_{i=1}^{k+1} \lambda_i x_i = \sum_{i=1}^{k} \lambda_i x_i + \lambda_{k+1} x_{k+1}.
> >      $$
> >
> >     Assuming $0 < \lambda_{k+1} < 1$, as otherwise, it reduces to
> >     previously considered cases, we have
> >
> >     $$
> >      x = \lambda_{k+1} x_{k+1} + (1 - \lambda_{k+1}) \bar{x}, 
> >      $$
> >
> >     where $\bar{x} = \sum_{i=1}^{k} \gamma_i x_i$ and
> >     $\gamma_i = \frac{\lambda_i}{1-\lambda_{k+1}} \geq 0, 1 \leq i \leq k$.
> >
> > 4.  Since $\lambda \in \Delta_{k+1}$, then
> >     $\gamma = [\gamma_1, \ldots, \gamma_k] \in \Delta_k$. Therefore
> >     $\bar{x} \in X$ and by the convexity of $f(x)$ and the induction
> >     hypothesis:
> >
> >     $$
> >      \begin{split}
> >      f\left( \sum_{i=1}^{k+1} \lambda_i x_i \right) = f\left( \lambda_{k+1} x_{k+1} + (1 - \lambda_{k+1})\bar{x} \right) &\leq \\ 
> >      \lambda_{k+1}f(x_{k+1}) + (1 - \lambda_{k+1})f(\bar{x}) \leq \sum_{i=1}^{k+1} \lambda_i f(x_i)&
> >      \end{split}
> >      $$
> >
> >     Thus, initial inequality is satisfied for $m = k + 1$ as well.
> >
> > </div>
> >
> > </div>
>
> </div>
>
> </div>

> [!EXAMPLE]
>
> ### Example
>
> <div>
>
> <div class="callout-example">
>
> - $f(x) = x^p, \;  p > 1,\;  x \in \mathbb{R}_+$
> - $f(x) = \|x\|^p,\;  p > 1, x \in \mathbb{R}^n$
> - $f(x) = e^{cx},\;  c \in \mathbb{R}, x \in \mathbb{R}$
> - $f(x) = -\ln x,\;  x \in \mathbb{R}_{++}$
> - $f(x) = x\ln x,\;  x \in \mathbb{R}_{++}$
> - The sum of the largest $k$ coordinates
>   $f(x) = x_{(1)} + \ldots + x_{(k)},\; x \in \mathbb{R}^n$
> - $f(X) = \lambda_{max}(X),\;  X = X^T$
> - $f(X) = - \log \det X, \;  X \in S^n_{++}$
>
> </div>
>
> </div>

### Epigraph

For the function $f(x)$, defined on $S \subseteq \mathbb{R}^n$, the
following set:

$$
\text{epi } f = \left\{[x,\mu] \in S \times \mathbb{R}: f(x) \le \mu\right\}
$$

is called **epigraph** of the function $f(x)$.

<div id="fig-epigraph">

![](epigraph.svg)

Figure 2: Epigraph of a function

</div>

> [!THEOREM]
>
> ### Convexity of the epigraph is the convexity of the function
>
> <div>
>
> <div class="callout-theorem">
>
> For a function $f(x)$, defined on a convex set $X$, to be convex on
> $X$, it is necessary and sufficient that the epigraph of $f$ is a
> convex set.
>
> > [!PROOF]
> >
> > ### Proof
> >
> > <div>
> >
> > <div class="callout-proof" collapse="true">
> >
> > 1.  **Necessity**: Assume $f(x)$ is convex on $X$. Take any two
> >     arbitrary points $[x_1, \mu_1] \in \text{epi}f$ and
> >     $[x_2, \mu_2] \in \text{epi}f$. Also take
> >     $0 \leq \lambda \leq 1$ and denote
> >     $x_{\lambda} = \lambda x_1 + (1 - \lambda) x_2, \mu_{\lambda} = \lambda \mu_1 + (1 - \lambda) \mu_2$.
> >     Then,
> >
> >     $$
> >      \lambda\begin{bmatrix}x_1\\ \mu_1\end{bmatrix} + (1 - \lambda)\begin{bmatrix}x_2\\ \mu_2\end{bmatrix} = \begin{bmatrix}x_{\lambda}\\ \mu_{\lambda}\end{bmatrix}.
> >      $$
> >
> >     From the convexity of the set $X$, it follows that
> >     $x_{\lambda} \in X$. Moreover, since $f(x)$ is a convex
> >     function,
> >
> >     $$
> >      f(x_{\lambda}) \leq \lambda f(x_1) + (1 - \lambda) f(x_2) \leq \lambda \mu_1 + (1 - \lambda) \mu_2 = \mu_{\lambda}
> >      $$
> >
> >     Inequality above indicates that
> >     $\begin{bmatrix}x_{\lambda}\\ \mu_{\lambda}\end{bmatrix} \in \text{epi}f$.
> >     Thus, the epigraph of $f$ is a convex set.
> >
> > 2.  **Sufficiency**: Assume the epigraph of $f$, $\text{epi}f$, is a
> >     convex set. Then, from the membership of the points
> >     $[x_1, \mu_1]$ and $[x_2, \mu_2]$ in the epigraph of $f$, it
> >     follows that
> >
> >     $$
> >       \begin{bmatrix}x_{\lambda}\\ \mu_{\lambda}\end{bmatrix} =  \lambda\begin{bmatrix}x_1\\ \mu_1\end{bmatrix} + (1 - \lambda)\begin{bmatrix}x_2\\ \mu_2\end{bmatrix} \in \text{epi}f
> >      $$
> >
> >     for any $0 \leq \lambda \leq 1$, i.e.,
> >     $f(x_{\lambda}) \leq \mu_{\lambda} = \lambda \mu_1 + (1 - \lambda) \mu_2$.
> >     But this is true for all $\mu_1 \geq f(x_1)$ and
> >     $\mu_2 \geq f(x_2)$, particularly when $\mu_1 = f(x_1)$ and
> >     $\mu_2 = f(x_2)$. Hence we arrive at the inequality
> >
> >     $$
> >      f(x_{\lambda}) = f (\lambda x_1 + (1 - \lambda) x_2) \leq \lambda f(x_1) + (1 - \lambda) f(x_2).
> >      $$
> >
> >     Since points $x_1 \in X$ and $x_2 \in X$ can be arbitrarily
> >     chosen, $f(x)$ is a convex function on $X$.
> >
> > </div>
> >
> > </div>
>
> </div>
>
> </div>

### Sublevel set

For the function $f(x)$, defined on $S \subseteq \mathbb{R}^n$, the
following set:

$$
\mathcal{L}_\beta = \left\{ x\in S : f(x) \le \beta\right\}
$$

is called **sublevel set** or Lebesgue set of the function $f(x)$.

<div id="fig-sublevel_set">

![](sublevel_set.svg)

Figure 3: Sublevel set of a function with respect to level $\beta$

</div>

## Criteria of convexity

### First-order differential criterion of convexity

The differentiable function $f(x)$ defined on the convex set
$S \subseteq \mathbb{R}^n$ is convex if and only if $\forall x,y \in S$:

$$
f(y) \ge f(x) + \nabla f^T(x)(y-x)
$$

Let $y = x + \Delta x$, then the criterion will become more tractable:

$$
f(x + \Delta x) \ge f(x) + \nabla f^T(x)\Delta x
$$

<div id="fig-convexity_criterion_1">

![](diff_conv.svg)

Figure 4: Convex function is greater or equal than Taylor linear
approximation at any point

</div>

### Second-order differential criterion of convexity

Twice differentiable function $f(x)$ defined on the convex set
$S \subseteq \mathbb{R}^n$ is convex if and only if
$\forall x \in \mathbf{int}(S) \neq \emptyset$:

$$
\nabla^2 f(x) \succeq 0
$$

In other words, $\forall y \in \mathbb{R}^n$:

$$
\langle y, \nabla^2f(x)y\rangle \geq 0
$$

### Connection with epigraph

The function is convex if and only if its epigraph is a convex set.

> [!EXAMPLE]
>
> ### Example
>
> <div>
>
> <div class="callout-example">
>
> Let a norm $\Vert \cdot \Vert$ be defined in the space $U$. Consider
> the set:
>
> $$
> K := \{(x,t) \in U \times \mathbb{R}^+ : \Vert x \Vert \leq t \}
> $$
>
> which represents the epigraph of the function
> $x \mapsto \Vert x \Vert$. This set is called the cone norm. According
> to the statement above, the set $K$ is convex.
>
> In the case where $U = \mathbb{R}^n$ and
> $\Vert x \Vert = \Vert x \Vert_2$ (Euclidean norm), the abstract set
> $K$ transitions into the set:
>
> $$
> \{(x,t) \in \mathbb{R}^n \times \mathbb{R}^+ : \Vert x \Vert_2 \leq t \}
> $$
>
> </div>
>
> </div>

### Connection with sublevel set

If $f(x)$ - is a convex function defined on the convex set
$S \subseteq \mathbb{R}^n$, then for any $\beta$ sublevel set
$\mathcal{L}_\beta$ is convex.

The function $f(x)$ defined on the convex set $S \subseteq \mathbb{R}^n$
is closed if and only if for any $\beta$ sublevel set
$\mathcal{L}_\beta$ is closed.

### Reduction to a line

$f: S \to \mathbb{R}$ is convex if and only if $S$ is a convex set and
the function $g(t) = f(x + tv)$ defined on
$\left\{ t \mid x + tv \in S \right\}$ is convex for any
$x \in S, v \in \mathbb{R}^n$, which allows checking convexity of the
scalar function to establish convexity of the vector function.

## Strong convexity

$f(x)$, **defined on the convex set** $S \subseteq \mathbb{R}^n$, is
called $\mu$-strongly convex (strongly convex) on $S$, if:

$$
f(\lambda x_1 + (1 - \lambda)x_2) \le \lambda f(x_1) + (1 - \lambda)f(x_2) - \frac{\mu}{2} \lambda (1 - \lambda)\|x_1 - x_2\|^2
$$

for any $x_1, x_2 \in S$ and $0 \le \lambda \le 1$ for some $\mu > 0$.

<div id="fig-strongly_convex">

![](strong_convexity.svg)

Figure 5: Strongly convex function is greater or equal than Taylor
quadratic approximation at any point

</div>

### Criteria of strong convexity

#### First-order differential criterion of strong convexity

Differentiable $f(x)$ defined on the convex set
$S \subseteq \mathbb{R}^n$ is $\mu$-strongly convex if and only if
$\forall x,y \in S$:

$$
f(y) \ge f(x) + \nabla f^T(x)(y-x) + \dfrac{\mu}{2}\|y-x\|^2
$$

Let $y = x + \Delta x$, then the criterion will become more tractable:

$$
f(x + \Delta x) \ge f(x) + \nabla f^T(x)\Delta x + \dfrac{\mu}{2}\|\Delta x\|^2
$$

#### Second-order differential criterion of strong convexity

Twice differentiable function $f(x)$ defined on the convex set
$S \subseteq \mathbb{R}^n$ is called $\mu$-strongly convex if and only
if $\forall x \in \mathbf{int}(S) \neq \emptyset$:

$$
\nabla^2 f(x) \succeq \mu I
$$

In other words:

$$
\langle y, \nabla^2f(x)y\rangle \geq \mu \|y\|^2
$$

> [!THEOREM]
>
> ### Theorem
>
> <div>
>
> <div class="callout-theorem">
>
> Let $f(x)$ be a differentiable function on a convex set
> $X \subseteq \mathbb{R}^n$. Then $f(x)$ is strongly convex on $X$ with
> a constant $\mu > 0$ if and only if
>
> $$ 
> f(x) - f(x_0) \geq \langle \nabla f(x_0), x - x_0 \rangle + \frac{\mu}{2} \| x - x_0 \|^2
> $$
>
> for all $x, x_0 \in X$.
>
> > [!PROOF]
> >
> > ### Proof
> >
> > <div>
> >
> > <div class="callout-proof" collapse="true">
> >
> > **Necessity**: Let $0 < \lambda \leq 1$. According to the definition
> > of a strongly convex function,
> >
> > $$ 
> > f(\lambda x + (1 - \lambda) x_0) \leq \lambda f(x) + (1 - \lambda) f(x_0) - \frac{\mu}{2} \lambda (1 - \lambda) \| x - x_0 \|^2 
> > $$
> >
> > or equivalently,
> >
> > $$ 
> > f(x) - f(x_0) - \frac{\mu}{2} (1 - \lambda) \| x - x_0 \|^2 \geq \frac{1}{\lambda} [f(\lambda x + (1 - \lambda) x_0) - f(x_0)] = 
> > $$
> >
> > $$ 
> > = \frac{1}{\lambda} [f(x_0 + \lambda(x - x_0)) - f(x_0)] = \frac{1}{\lambda} [\lambda \langle \nabla f(x_0), x - x_0 \rangle + o(\lambda)] = 
> > $$
> >
> > $$ 
> > = \langle \nabla f(x_0), x - x_0 \rangle + \frac{o(\lambda)}{\lambda}. 
> > $$
> >
> > Thus, taking the limit as $\lambda \downarrow 0$, we arrive at the
> > initial statement.
> >
> > **Sufficiency**: Assume the inequality in the theorem is satisfied
> > for all $x, x_0 \in X$. Take
> > $x_0 = \lambda x_1 + (1 - \lambda) x_2$, where $x_1, x_2 \in X$,
> > $0 \leq \lambda \leq 1$. According to the inequality, the following
> > inequalities hold:
> >
> > $$ 
> > f(x_1) - f(x_0) \geq \langle \nabla f(x_0), x_1 - x_0 \rangle + \frac{\mu}{2} \| x_1 - x_0 \|^2, 
> > $$
> >
> > $$ 
> > f(x_2) - f(x_0) \geq \langle \nabla f(x_0), x_2 - x_0 \rangle + \frac{\mu}{2} \| x_2 - x_0 \|^2. 
> > $$
> >
> > Multiplying the first inequality by $\lambda$ and the second by
> > $1 - \lambda$ and adding them, considering that
> >
> > $$ 
> > x_1 - x_0 = (1 - \lambda)(x_1 - x_2), \quad x_2 - x_0 = \lambda(x_2 - x_1), 
> > $$
> >
> > and
> > $\lambda(1 - \lambda)^2 + \lambda^2(1 - \lambda) = \lambda(1 - \lambda)$,
> > we get
> >
> > $$ 
> > \begin{split}
> > \lambda f(x_1) + (1 - \lambda) f(x_2) - f(x_0) - \frac{\mu}{2} \lambda (1 - \lambda) \| x_1 - x_2 \|^2 \geq \\
> > \langle \nabla f(x_0), \lambda x_1 + (1 - \lambda) x_2 - x_0 \rangle = 0. 
> > \end{split}
> > $$
> >
> > Thus, inequality from the definition of a strongly convex function
> > is satisfied. It is important to mention, that $\mu = 0$ stands for
> > the convex case and corresponding differential criterion.
> >
> > </div>
> >
> > </div>
>
> </div>
>
> </div>

> [!THEOREM]
>
> ### Theorem
>
> <div>
>
> <div class="callout-theorem">
>
> Let $X \subseteq \mathbb{R}^n$ be a convex set, with
> $\text{int}X \neq \emptyset$. Furthermore, let $f(x)$ be a twice
> continuously differentiable function on $X$. Then $f(x)$ is strongly
> convex on $X$ with a constant $\mu > 0$ if and only if
>
> $$
> \langle y, \nabla^2 f(x) y \rangle \geq \mu \| y \|^2 \quad 
> $$
>
> for all $x \in X$ and $y \in \mathbb{R}^n$.
>
> > [!PROOF]
> >
> > ### Proof
> >
> > <div>
> >
> > <div class="callout-proof" collapse="true">
> >
> > The target inequality is trivial when $y = \mathbf{0}_n$, hence we
> > assume $y \neq \mathbf{0}_n$.
> >
> > **Necessity**: Assume initially that $x$ is an interior point of
> > $X$. Then $x + \alpha y \in X$ for all $y \in \mathbb{R}^n$ and
> > sufficiently small $\alpha$. Since $f(x)$ is twice differentiable,
> >
> > $$
> > f(x + \alpha y) = f(x) + \alpha \langle \nabla f(x), y \rangle + \frac{\alpha^2}{2} \langle y, \nabla^2 f(x) y \rangle + o(\alpha^2).
> > $$
> >
> > Based on the first order criterion of strong convexity, we have
> >
> > $$
> > \frac{\alpha^2}{2} \langle y, \nabla^2 f(x) y \rangle + o(\alpha^2) = f(x + \alpha y) - f(x) - \alpha \langle \nabla f(x), y \rangle \geq \frac{\mu}{2} \alpha^2 \| y \|^2.
> > $$
> >
> > This inequality reduces to the target inequality after dividing both
> > sides by $\alpha^2$ and taking the limit as $\alpha \downarrow 0$.
> >
> > If $x \in X$ but $x \notin \text{int}X$, consider a sequence
> > $\{x_k\}$ such that $x_k \in \text{int}X$ and $x_k \rightarrow x$ as
> > $k \rightarrow \infty$. Then, we arrive at the target inequality
> > after taking the limit.
> >
> > **Sufficiency**: Using Taylor’s formula with the Lagrange remainder
> > and the target inequality, we obtain for $x + y \in X$:
> >
> > $$
> > f(x + y) - f(x) - \langle \nabla f(x), y \rangle = \frac{1}{2} \langle y, \nabla^2 f(x + \alpha y) y \rangle \geq \frac{\mu}{2} \| y \|^2, 
> > $$
> >
> > where $0 \leq \alpha \leq 1$. Therefore,
> >
> > $$
> > f(x + y) - f(x) \geq \langle \nabla f(x), y \rangle + \frac{\mu}{2} \| y \|^2.
> > $$
> >
> > Consequently, by the first order criterion of strong convexity, the
> > function $f(x)$ is strongly convex with a constant $\mu$. It is
> > important to mention, that $\mu = 0$ stands for the convex case and
> > corresponding differential criterion.
> >
> > </div>
> >
> > </div>
>
> </div>
>
> </div>

## Facts

- $f(x)$ is called (strictly) concave, if the function $-f(x)$ - is
  (strictly) convex.

- Jensen’s inequality for the convex functions:

  $$
    f \left( \sum\limits_{i=1}^n \alpha_i x_i \right) \leq \sum\limits_{i=1}^n \alpha_i f(x_i)
    $$

  for $\alpha_i \geq 0; \quad \sum\limits_{i=1}^n \alpha_i = 1$
  (probability simplex)  
  For the infinite dimension case:

  $$
    f \left( \int\limits_{S} x p(x)dx \right) \leq \int\limits_{S} f(x)p(x)dx
    $$

  If the integrals exist and
  $p(x) \geq 0, \quad \int\limits_{S} p(x)dx = 1$.

- If the function $f(x)$ and the set $S$ are convex, then any local
  minimum $x^* = \text{arg}\min\limits_{x \in S} f(x)$ will be the
  global one. Strong convexity guarantees the uniqueness of the
  solution.

- Let $f(x)$ - be a convex function on a convex set
  $S \subseteq \mathbb{R}^n$. Then $f(x)$ is continuous
  $\forall x \in \textbf{ri}(S)$.

## Operations that preserve convexity

- Non-negative sum of the convex functions:
  $\alpha f(x) + \beta g(x), (\alpha \geq 0 , \beta \geq 0)$.
- Composition with affine function $f(Ax + b)$ is convex, if $f(x)$ is
  convex.
- Pointwise maximum (supremum) of any number of functions: If
  $f_1(x), \ldots, f_m(x)$ are convex, then
  $f(x) = \max \{f_1(x), \ldots, f_m(x)\}$ is convex.
- If $f(x,y)$ is convex on $x$ for any $y \in Y$:
  $g(x) = \underset{y \in Y}{\operatorname{sup}}f(x,y)$ is convex.
- If $f(x)$ is convex on $S$, then $g(x,t) = t f(x/t)$ - is convex with
  $x/t \in S, t > 0$.
- Let $f_1: S_1 \to \mathbb{R}$ and $f_2: S_2 \to \mathbb{R}$, where
  $\operatorname{range}(f_1) \subseteq S_2$. If $f_1$ and $f_2$ are
  convex, and $f_2$ is increasing, then $f_2 \circ f_1$ is convex on
  $S_1$.

## Other forms of convexity

- Log-convex: $\log f$ is convex; Log convexity implies convexity.
- Log-concavity: $\log f$ concave; **not** closed under addition!
- Exponentially convex: $[f(x_i + x_j )] \succeq 0$, for
  $x_1, \ldots , x_n$
- Operator convex:
  $f(\lambda X + (1 − \lambda )Y ) \preceq \lambda f(X) + (1 − \lambda )f(Y)$
- Quasiconvex:
  $$f(\lambda x + (1 − \lambda) y) \leq \max \{f(x), f(y)\}$$
- Pseudoconvex:
  $\langle \nabla f(y), x − y \rangle \geq 0 \longrightarrow f(x) \geq f(y)$
- Discrete convexity: $f : \mathbb{Z}^n \to \mathbb{Z}$; “convexity +
  matroid theory.”

> [!EXAMPLE]
>
> ### Example
>
> <div>
>
> <div class="callout-example">
>
> Show, that $f(x) = c^\top x + b$ is convex and concave.
>
> > [!SOLUTION]
> >
> > ### Solution
> >
> > <div>
> >
> > <div class="callout-solution" collapse="true">
> >
> > <br/><br/> <br/><br/> <br/><br/>
> >
> > </div>
> >
> > </div>
>
> </div>
>
> </div>

> [!EXAMPLE]
>
> ### Example
>
> <div>
>
> <div class="callout-example">
>
> Show, that $f(x) = x^\top Ax$, where $A\succeq 0$ - is convex on
> $\mathbb{R}^n$.
>
> > [!SOLUTION]
> >
> > ### Solution
> >
> > <div>
> >
> > <div class="callout-solution" collapse="true">
> >
> > <br/><br/> <br/><br/> <br/><br/>
> >
> > </div>
> >
> > </div>
>
> </div>
>
> </div>

> [!EXAMPLE]
>
> ### Example
>
> <div>
>
> <div class="callout-example">
>
> Show, that $f(A) = \lambda_{max}(A)$ - is convex, if $A \in S^n$.
>
> > [!SOLUTION]
> >
> > ### Solution
> >
> > <div>
> >
> > <div class="callout-solution" collapse="true">
> >
> > <br/><br/> <br/><br/> <br/><br/>
> >
> > </div>
> >
> > </div>
>
> </div>
>
> </div>

> [!EXAMPLE]
>
> ### Example
>
> <div>
>
> <div class="callout-example">
>
> PL inequality holds if the following condition is satisfied for some
> \$ \> 0 $,$\$ f(x) ^2 (f(x) - f^\*) x $$
> The example of a function, that satisfies the PL-condition, but is not convex.
> $$ f(x,y) = \$\$
>
> <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
>         <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.24.1.min.js"></script>                <div id="03dd2c45-94d2-4a52-b502-201c42b7b355" class="plotly-graph-div" style="height:100%; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("03dd2c45-94d2-4a52-b502-201c42b7b355")) {                    Plotly.newPlot(                        "03dd2c45-94d2-4a52-b502-201c42b7b355",                        [{"colorscale":[[0.0,"rgb(243, 231, 155)"],[0.16666666666666666,"rgb(250, 196, 132)"],[0.3333333333333333,"rgb(248, 160, 126)"],[0.5,"rgb(235, 127, 134)"],[0.6666666666666666,"rgb(206, 102, 147)"],[0.8333333333333334,"rgb(160, 89, 160)"],[1.0,"rgb(92, 83, 165)"]],"x":[[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0],[-5.0,-4.583333333333333,-4.166666666666667,-3.75,-3.333333333333333,-2.9166666666666665,-2.5,-2.083333333333333,-1.6666666666666665,-1.25,-0.833333333333333,-0.4166666666666661,0.0,0.41666666666666696,0.8333333333333339,1.25,1.666666666666667,2.083333333333334,2.5,2.916666666666667,3.333333333333334,3.75,4.166666666666668,4.583333333333334,5.0]],"y":[[-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0],[-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333,-1.8333333333333333],[-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667,-1.6666666666666667],[-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5,-1.5],[-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335,-1.3333333333333335],[-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667,-1.1666666666666667],[-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0],[-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335,-0.8333333333333335],[-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667,-0.6666666666666667],[-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5],[-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335,-0.3333333333333335],[-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674,-0.16666666666666674],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652,0.16666666666666652],[0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304,0.33333333333333304],[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],[0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665,0.6666666666666665],[0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333,0.833333333333333],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],[1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665,1.1666666666666665],[1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333,1.333333333333333],[1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5,1.5],[1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665,1.6666666666666665],[1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333,1.833333333333333],[2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0]],"z":[[4.37761643159539,4.475086194821239,4.074806224268477,3.3064638080259305,2.3992939999882257,1.5788037022903323,0.9821401654262806,0.6367525234636243,0.5046025856742399,0.552316665175561,0.79357718061152,1.2724678118569872,2.0,2.8913260661014863,3.754284593395669,4.348255142597906,4.486234416681301,4.122765289228686,3.376028741842106,2.4709405583285236,1.6370221484862848,1.0202185330565563,0.6557957953131167,0.5083507070501629,0.5419193329428361],[3.8983512747070885,3.990361105053001,3.612903011950892,2.891759143791096,2.0480882283978676,1.2965316268474791,0.7624410783324954,0.46255861092605743,0.35105946752175615,0.3910363239570475,0.5974955450330817,1.02047579467273,1.6805555555555554,2.5044291943968537,3.3114773400852187,3.8706465949275306,4.000888645944894,3.658070312877363,2.956838940047002,2.1143237448824883,1.3493390311877542,0.796034308402502,0.47881011874181245,0.3541869079295132,0.38229560094224807],[3.446863895596566,3.5334137930625387,3.178777577411086,2.504832257334039,1.7246602345852868,1.042037329182404,0.5705197690164883,0.3161424761662685,0.22529412714705044,0.25753376051631205,0.42919168723242124,0.7962615552662509,1.388888888888889,2.1453101004699997,2.8964478645525458,3.420815825034932,3.543320652986267,3.2211531143038203,2.565426916029677,1.78548470921423,1.089433691667002,0.5996278615262262,0.329602219948286,0.22780088658664152,0.2504496467194379],[3.023154294263821,3.104244258849855,2.7724299206490577,2.1456831486547587,1.4290100185504833,0.8153208092951064,0.40637623747825874,0.1975041191842572,0.12730656455012232,0.15180897485335412,0.28866560720953843,0.5998250936375493,1.125,1.8139687843209236,2.50919616679765,2.9987628329201126,3.1135304378054176,2.812013693508053,2.201792669790128,1.4844234513237498,0.8573061299240277,0.43099919242772794,0.20817209893253708,0.12919264302154748,0.14638147027440543],[2.627222470708854,2.7028525024149497,2.393860041664807,1.8143118177532576,1.1611375802934583,0.6163820671855867,0.27001048371780717,0.10664353998002375,0.05709677973097208,0.0738619669681741,0.17591730496443356,0.4311664097866257,0.8888888888888891,1.5104052459496253,2.149722246820533,2.6044876185830708,2.711518000402345,2.430652050490065,1.8659362013283578,1.2111399712110476,0.652956345958831,0.29014830110700757,0.11451975569456611,0.0583621772342313,0.07009107160715077],[2.2590684249316633,2.329238523757821,2.0430679404583327,1.5107182646295338,0.921042919814211,0.4452211028538447,0.16142250773513314,0.043560738553567985,0.014664772689599533,0.023692736860771755,0.09094678049710633,0.29028550371347966,0.6805555555555557,1.2346194853561039,1.8180261046211939,2.2379901820238057,2.3372833407770512,2.0770681852498543,1.5578575106443648,0.9656342688761228,0.47638433977141176,0.17707518756406476,0.0486451902343728,0.015309489224692815,0.02157845071767381],[1.9186921569322517,1.9834023228784705,1.7200536170296374,1.2349024892835871,0.708726037112741,0.3018379162998804,0.08061230953023696,0.008255714904890013,0.000010543426004787861,0.001301284531147215,0.033754033807556885,0.1771823754181114,0.5,0.9866115025403611,1.5141077401996315,1.8992705232423197,1.9908264589295346,1.7512620977874205,1.2775565977381498,0.747906344318976,0.32759011136177046,0.09177985179889979,0.01054840255195728,0.000034578992932129814,0.0008436076059746448],[1.6060936667106178,1.6653438997768981,1.4248170713787198,0.9868644917154189,0.5241869321890491,0.18623250752369405,0.027579889103118625,0.0007284690339898373,0.013134091940187808,0.006687609979300454,0.004339064895785268,0.09185702490052108,0.3472222222222223,0.766381297502396,1.2379671535558476,1.5883286422386111,1.6721473548597963,1.4532337881027655,1.0250334626097128,0.557956197539607,0.20657366072990707,0.034262293811512676,0.00022939264731956457,0.012537446538949212,0.007886542272053258],[1.321272954266761,1.3750632544531032,1.1573583035055794,0.7666042719250284,0.36742560504313504,0.09840487652528533,0.002325246453778002,0.020979000940867437,0.05403541823214863,0.03985171320523148,0.002701873761791395,0.0343094521607084,0.22222222222222227,0.5739288702422082,0.9896043446898416,1.3051645390126798,1.3812460285678354,1.1829832561958877,0.8002881052590534,0.3957838285380157,0.11333498787582132,0.004522513601903266,0.017688160520459618,0.052818091862744096,0.042707254715909665],[1.0642300196006824,1.112560386907086,0.9176773134102174,0.5741218299124152,0.23844205567499857,0.03835502330465442,0.004848381582215181,0.06900731062552283,0.12271452230188726,0.10079359420894031,0.028842460405575324,0.004539657198673523,0.125,0.40925422075979845,0.7690193136016128,1.0497782135645266,1.1181224800536522,0.9405105020667879,0.6033205256861717,0.26138923731420216,0.04787409279951336,0.002560511170071658,0.06292470617137748,0.12087651496431678,0.10530574493754387],[0.8349648627123818,0.8778352971388468,0.7057741010926332,0.40941716567758046,0.13723628408464006,0.0060829478618013265,0.035149294488430106,0.14481339808795593,0.21917140414940353,0.18951325299042682,0.08276082482713697,0.0025476400144164297,0.05555555555555561,0.2723573490551666,0.5762120602911622,0.8221696658941512,0.8827767093172472,0.725815525715466,0.4341307238910679,0.1547724238681665,0.010190975500983239,0.0283762865160178,0.135939029600073,0.2167127158436671,0.19568201293695575],[0.6334774836018584,0.6708879851483852,0.5216486665528262,0.2724902792205231,0.06380829027205917,0.0015886501967259836,0.09322798517242285,0.2483972633281669,0.34340606377469773,0.30601068954969124,0.16445696702647647,0.02833340060793712,0.013888888888888902,0.1632382551283124,0.41118258475848934,0.6223388960015535,0.6752087163586196,0.5388983271419218,0.29271869987374177,0.07593338819990854,0.0002856359802308549,0.08196983963974176,0.23673113080654645,0.3403266945007954,0.3138360587141455],[0.4597678822691131,0.4917184509357013,0.36530100979079727,0.16334117054124353,0.018158074237256103,0.024872130309428444,0.1790844536341934,0.37975890634615567,0.4954185011777697,0.4502859038867334,0.27393088700359375,0.08189693897923561,0.0,0.08189693897923594,0.2739308870035942,0.4502859038867334,0.4954185011777697,0.3797589063461553,0.1790844536341934,0.02487213030942835,0.018158074237256273,0.16334117054124353,0.36530100979079766,0.49171845093570143,0.4597678822691131],[0.3138360587141457,0.34032669450079545,0.23673113080654629,0.08196983963974185,0.00028563598023083895,0.07593338819990861,0.2927186998737416,0.538898327141922,0.6752087163586192,0.6223388960015531,0.4111825847584887,0.1632382551283118,0.013888888888888864,0.02833340060793737,0.1644569670264769,0.3060106895496914,0.3434060637746979,0.24839726332816672,0.09322798517242295,0.0015886501967259728,0.06380829027205942,0.27249027922052294,0.5216486665528266,0.6708879851483849,0.6334774836018584],[0.19568201293695603,0.21671271584366733,0.135939029600073,0.028376286516017906,0.010190975500983303,0.1547724238681665,0.4341307238910675,0.725815525715466,0.8827767093172465,0.8221696658941506,0.5762120602911613,0.27235734905516573,0.055555555555555455,0.002547640014416521,0.08276082482713737,0.1895132529904271,0.21917140414940384,0.14481339808795593,0.035149294488430224,0.006082947861801324,0.13723628408464028,0.4094171656775801,0.7057741010926332,0.8778352971388462,0.8349648627123812],[0.10530574493754387,0.12087651496431673,0.06292470617137731,0.002560511170071658,0.047874092799513636,0.26138923731420244,0.6033205256861717,0.9405105020667884,1.1181224800536522,1.0497782135645266,0.7690193136016122,0.4092542207597977,0.125,0.004539657198673443,0.02884246040557546,0.10079359420894031,0.12271452230188726,0.06900731062552268,0.004848381582215181,0.038355023304654526,0.23844205567499918,0.5741218299124152,0.917677313410218,1.112560386907086,1.0642300196006824],[0.04270725471590973,0.05281809186274413,0.017688160520459576,0.004522513601903245,0.11333498787582162,0.39578382853801586,0.800288105259053,1.1829832561958882,1.381246028567835,1.3051645390126796,0.9896043446898404,0.5739288702422072,0.22222222222222213,0.034309452160708125,0.0027018737617914524,0.039851713205231544,0.054035418232148705,0.02097900094086739,0.002325246453777987,0.0984048765252854,0.3674256050431356,0.7666042719250279,1.15735830350558,1.3750632544531027,1.321272954266761],[0.007886542272053314,0.012537446538949264,0.00022939264731956457,0.03426229381151256,0.20657366072990735,0.557956197539607,1.0250334626097122,1.4532337881027655,1.6721473548597956,1.5883286422386103,1.2379671535558463,0.7663812975023944,0.347222222222222,0.09185702490052054,0.004339064895785175,0.006687609979300505,0.013134091940187881,0.0007284690339898373,0.02757988910311852,0.18623250752369405,0.5241869321890495,0.9868644917154182,1.4248170713787198,1.6653438997768972,1.606093666710617],[0.0008436076059746448,0.000034578992932130736,0.010548402551957345,0.09177985179889979,0.3275901113617712,0.7479063443189765,1.2775565977381498,1.7512620977874214,1.9908264589295346,1.8992705232423197,1.5141077401996306,0.9866115025403599,0.5,0.17718237541811094,0.03375403380755674,0.001301284531147215,0.000010543426004787861,0.00825571490489007,0.08061230953023696,0.30183791629988077,0.708726037112742,1.2349024892835871,1.7200536170296383,1.9834023228784705,1.9186921569322517],[0.02157845071767376,0.015309489224692795,0.048645190234372866,0.17707518756406465,0.4763843397714124,0.9656342688761231,1.5578575106443646,2.0770681852498543,2.3372833407770504,2.2379901820238057,1.818026104621192,1.2346194853561026,0.6805555555555554,0.2902855037134789,0.090946780497106,0.023692736860771706,0.014664772689599495,0.04356073855356805,0.16142250773513303,0.4452211028538449,0.9210429198142116,1.510718264629533,2.0430679404583336,2.329238523757821,2.2590684249316633],[0.0700910716071506,0.05836217723423119,0.11451975569456611,0.29014830110700723,0.6529563459588316,1.2111399712110476,1.865936201328357,2.430652050490065,2.711518000402345,2.60448761858307,2.1497222468205313,1.5104052459496229,0.8888888888888885,0.43116640978662457,0.17591730496443297,0.07386196696817392,0.05709677973097193,0.10664353998002375,0.27001048371780684,0.6163820671855867,1.161137580293459,1.8143118177532567,2.393860041664807,2.7028525024149483,2.627222470708853],[0.14638147027440543,0.12919264302154754,0.20817209893253738,0.43099919242772794,0.8573061299240289,1.4844234513237504,2.201792669790128,2.812013693508054,3.1135304378054176,2.9987628329201126,2.5091961667976492,1.813968784320922,1.125,0.5998250936375483,0.28866560720953804,0.15180897485335412,0.12730656455012232,0.19750411918425748,0.40637623747825874,0.815320809295107,1.4290100185504848,2.1456831486547587,2.7724299206490586,3.104244258849855,3.023154294263821],[0.2504496467194378,0.22780088658664147,0.32960221994828615,0.5996278615262262,1.0894336916670033,1.7854847092142305,2.565426916029676,3.2211531143038203,3.543320652986266,3.420815825034932,2.8964478645525435,2.145310100469998,1.3888888888888886,0.7962615552662495,0.4291916872324205,0.2575337605163119,0.22529412714705027,0.3161424761662687,0.570519769016488,1.0420373291824043,1.7246602345852877,2.504832257334038,3.178777577411087,3.5334137930625387,3.446863895596566],[0.3822956009422479,0.35418690792951313,0.4788101187418127,0.796034308402502,1.3493390311877556,2.1143237448824883,2.956838940047002,3.658070312877364,4.000888645944894,3.8706465949275297,3.311477340085216,2.5044291943968515,1.680555555555555,1.0204757946727283,0.5974955450330809,0.39103632395704735,0.351059467521756,0.46255861092605766,0.7624410783324951,1.2965316268474796,2.0480882283978685,2.891759143791095,3.6129030119508934,3.9903611050529997,3.8983512747070885],[0.5419193329428361,0.5083507070501629,0.6557957953131173,1.0202185330565563,1.6370221484862864,2.4709405583285244,3.376028741842106,4.122765289228687,4.486234416681301,4.348255142597906,3.7542845933956674,2.891326066101484,2.0,1.2724678118569857,0.7935771806115195,0.552316665175561,0.5046025856742399,0.6367525234636249,0.9821401654262806,1.5788037022903332,2.399293999988228,3.3064638080259305,4.074806224268479,4.475086194821239,4.37761643159539]],"type":"surface"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"scene":{"xaxis":{"title":{"text":"X"}},"yaxis":{"title":{"text":"Y"}},"zaxis":{"title":{"text":"f(x,y)"}}},"title":{"text":"Non-convex PL function f(x, y) = (y - sin(x))²\u002f2"}},                        {"displaylogo": false, "toImageButtonOptions": {"format": "svg", "filename": "fmin", "height": null, "width": null, "scale": 1}, "modeBarButtonsToRemove": ["select2d", "lasso2d"], "modeBarButtonsToAdd": ["drawopenpath", "eraseshape"], "responsive": true}                    )                };                            </script>        </div>
>
> </div>
>
> </div>

## References

- [Steven Boyd
  lectures](http://web.stanford.edu/class/ee364a/lectures/functions.pdf)
- [Suvrit Sra lectures](http://suvrit.de/teach/ee227a/lect3.pdf)
- [Martin Jaggi
  lectures](https://github.com/epfml/OptML_course/raw/master/slides/lecture01.pdf)
- Example of Pl non-convex function [Open in
  Colab](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/PL_function.ipynb)
